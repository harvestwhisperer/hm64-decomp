import argparse
import csv
import json
import numpy as np
import os
import re
import sys

from pathlib import Path

ROM_PATH = Path(__file__).parent / "../../baserom.us.z64"
CSV_PATH = Path(__file__).parent / "text_addresses.csv"

VERBOSE = "--verbose" in sys.argv
LITERAL_MODE = "--literal" in sys.argv  # Output exact control codes for recompilation

rom = None

def set_rom():
    global rom
    rom = memoryview(ROM_PATH.read_bytes())

CHAR_MAP = {

    # --- Row 1 (Hiragana) ---
    0x0B: 'ã‚', 0x0C: 'ã„', 0x0D: 'ã†', 0x0E: 'ãˆ', 0x0F: 'ãŠ',
    0x10: 'ã‹', 0x11: 'ã', 0x12: 'ã', 0x13: 'ã‘', 0x14: 'ã“',
    0x15: 'ã•', 0x16: 'ã—', 0x17: 'ã™', 0x18: 'ã›', 0x19: 'ã', 0x1A: 'ãŸ',

    # --- Row 2 ---
    0x1B: 'ã¡', 0x1C: 'ã¤', 0x1D: 'ã¦', 0x1E: 'ã¨', 0x1F: 'ãª',
    0x20: 'ã«', 0x21: 'ã¬', 0x22: 'ã­', 0x23: 'ã®', 0x24: 'ã¯',
    0x25: 'ã²', 0x26: 'ãµ', 0x27: 'ã¸', 0x28: 'ã»', 0x29: 'ã¾', 0x2A: 'ã¿',

    # --- Row 3 ---
    0x2B: 'ã‚€', 0x2C: 'ã‚', 0x2D: 'ã‚‚', 0x2E: 'ã‚„', 0x2F: 'ã‚†',
    0x30: 'ã‚ˆ', 0x31: 'ã‚‰', 0x32: 'ã‚Š', 0x33: 'ã‚‹', 0x34: 'ã‚Œ',
    0x35: 'ã‚', 0x36: 'ã‚', 0x37: 'ã‚’', 0x38: 'ã‚“', 0x39: 'ãŒ', 0x3A: 'ãŽ',

    # --- Row 4 ---
    0x3B: 'ã', 0x3C: 'ã’', 0x3D: 'ã”', 0x3E: 'ã–', 0x3F: 'ã˜',
    0x40: 'ãš', 0x41: 'ãœ', 0x42: 'ãž', 0x43: 'ã ', 0x44: 'ã¢',
    0x45: 'ã¥', 0x46: 'ã§', 0x47: 'ã©', 0x48: 'ã°', 0x49: 'ã³', 0x4A: 'ã¶',

    # --- Row 5 ---
    0x4B: 'ã¹', 0x4C: 'ã¼', 0x4D: 'ã±', 0x4E: 'ã´', 0x4F: 'ã·',
    0x50: 'ãº', 0x51: 'ã½', 0x52: 'ã‚ƒ', 0x53: 'ã‚…', 0x54: 'ã‚‡',
    0x55: 'ã£', 0x56: 'ã', 0x57: 'ãƒ', 0x58: 'ã…', 0x59: 'ã‡', 0x5A: 'ã‰',

    # --- Row 6 (Katakana Start) ---
    0x5B: 'ã‚¢', 0x5C: 'ã‚¤', 0x5D: 'ã‚¦', 0x5E: 'ã‚¨', 0x5F: 'ã‚ª',
    0x60: 'ã‚«', 0x61: 'ã‚­', 0x62: 'ã‚¯', 0x63: 'ã‚±', 0x64: 'ã‚³',
    0x65: 'ã‚µ', 0x66: 'ã‚·', 0x67: 'ã‚¹', 0x68: 'ã‚»', 0x69: 'ã‚½', 0x6A: 'ã‚¿',

    # --- Row 7 ---
    0x6B: 'ãƒ', 0x6C: 'ãƒ„', 0x6D: 'ãƒ†', 0x6E: 'ãƒˆ', 0x6F: 'ãƒŠ',
    0x70: 'ãƒ‹', 0x71: 'ãƒŒ', 0x72: 'ãƒ', 0x73: 'ãƒŽ', 0x74: 'ãƒ',
    0x75: 'ãƒ’', 0x76: 'ãƒ•', 0x77: 'ãƒ˜', 0x78: 'ãƒ›', 0x79: 'ãƒž', 0x7A: 'ãƒŸ',

    # --- Row 8 ---
    0x7B: 'ãƒ ', 0x7C: 'ãƒ¡', 0x7D: 'ãƒ¢', 0x7E: 'ãƒ¤', 0x7F: 'ãƒ¦',
    0x80: 'ãƒ¨', 0x81: 'ãƒ©', 0x82: 'ãƒª', 0x83: 'ãƒ«', 0x84: 'ãƒ¬',
    0x85: 'ãƒ­', 0x86: 'ãƒ¯', 0x87: 'ãƒ²', 0x88: 'ãƒ³', 0x89: 'ã‚¬', 0x8A: 'ã‚®',

    # --- Row 9 ---
    0x8B: 'ã‚°', 0x8C: 'ã‚²', 0x8D: 'ã‚´', 0x8E: 'ã‚¶', 0x8F: 'ã‚¸',
    0x90: 'ã‚º', 0x91: 'ã‚¼', 0x92: 'ã‚¾', 0x93: 'ãƒ€', 0x94: 'ãƒ‚',
    0x95: 'ãƒ…', 0x96: 'ãƒ‡', 0x97: 'ãƒ‰', 0x98: 'ãƒ', 0x99: 'ãƒ“', 0x9A: 'ãƒ–',

    # --- Row 10 ---
    0x9B: 'ãƒ™', 0x9C: 'ãƒœ', 0x9D: 'ãƒ‘', 0x9E: 'ãƒ”', 0x9F: 'ãƒ—',
    0xA0: 'ãƒš', 0xA1: 'ãƒ', 0xA2: 'ãƒ´', 0xA3: 'ãƒ£', 0xA4: 'ãƒ¥',
    0xA5: 'ãƒ§', 0xA6: 'ãƒƒ', 0xA7: 'ã‚¡', 0xA8: 'ã‚£', 0xA9: 'ã‚¥', 0xAA: 'ã‚§',

    0xAB: 'ã‚©',

    0xAC: 'A',
    0xAD: 'B', 
    0xAE: 'C',
    0xAF: 'D',
    0xB0: 'E',
    0xB1: 'F',
    0xB2: 'G',
    0xB3: 'H',
    0xB4: 'I',
    0xB5: 'J',
    0xB6: 'K',
    0xB7: 'L',
    0xB8: 'M',
    0xB9: 'N',
    0xBA: 'O',
    0xBB: 'P',
    0xBC: 'Q',
    0xBD: 'R',
    0xBE: 'S',
    0xBF: 'T',
    0xC0: 'U',
    0xC1: 'V',
    0xC2: 'W',
    0xC3: 'X',
    0xC4: 'Y',
    0xC5: 'Z',
    0xC6: 'a',
    0xC7: 'b',
    0xC8: 'c',
    0xC9: 'd',
    0xCA: 'e',
    0xCB: 'f',
    0xCC: 'g',
    0xCD: 'h',
    0xCE: 'i',
    0xCF: 'j',
    0xD0: 'k',
    0xD1: 'l',
    0xD2: 'm',
    0xD3: 'n',
    0xD4: 'o',
    0xD5: 'p',
    0xD6: 'q',
    0xD7: 'r',
    0xD8: 's',
    0xD9: 't',
    0xDA: 'u',
    0xDB: 'v',
    0xDC: 'w',
    0xDD: 'x',
    0xDE: 'y',
    0xDF: 'z',
    0xE0: '1',
    0xE1: '2',
    0xE2: '3',
    0xE3: '4',
    0xE4: '5',
    0xE5: '6',
    0xE6: '7',
    0xE7: '8',
    0xE8: '9',
    0xE9: '0',
    0xEA: '?',
    0xEB: '!', 
    0xEC: '-',
    0xEF: ',',
    0xF0: '.',
    0xF1: '/',
    0xF2: 'â˜†', 
    0xF3: 'â˜…', 
    0xF4: '&',
    0xF5: 'â™¡', 
    0xF6: 'â™¥', 
    0xF7: 'á²', # tear drop; alternative: ðŸ’§
    0xF8: 'âˆ´', # paw print; alternative: ðŸ¾
    0xF9: ' ',
    0xFA: 'â€»',   
    0xFB: 'â—‹', 
    0xFC: 'â„ƒ', 
    0xFD: 'æ˜¥', 
    0xFE: 'å¤', 
    0xFF: 'ç§‹', 
    0x100: 'å†¬', 
    0x101: 'â€”',
    0x102: 'Ã—',
    0x103: ':',
    0x104: ';', 
    0x105: 'â€¦', 
    0x106: "â€¥",
    0x107: 'â€œ',  
    0x108: 'â€', 
    # 0x109: '', # left diagonal unused 
    # 0x10A: '', # right diagonal unused

    # --- Row 17 ---
    0x10B: '(', 0x10C: ")", 0x10D: 'â™ª', 0x10E: 'â€™', 0x10F: 'æ—¥', 
    0x110: 'æœˆ', 0x111: 'Â¥',  0x112: '%', 0x113: '#', 0x114: '+', 
    0x115: 'æœ', 0x116: 'æ˜¼', 0x117: 'å¤•', 0x118: 'å¤œ', 0x119: 'æ™‚', 0x11A: 'é–“',

    # --- Row 18 ---
    0x11B: 'åˆ†', 0x11C: 'å¹´', 0x11D: 'æ˜”', 0x11E: 'æ˜¨', 0x11F: 'ç«', 
    0x120: 'æ°´', 0x121: 'æœ¨', 0x122: 'å±±', 0x123: 'å·', 0x124: 'æ± ', 
    0x125: 'æµ·', 0x126: 'é¢¨', 0x127: 'æ˜Ÿ', 0x128: 'ç©º', 0x129: 'å…‰', 0x12A: 'ç”º',

    # --- Row 19 ---
    0x12B: 'æ‘', 0x12C: 'åº—', 0x12D: 'çˆ¶', 0x12E: 'æ¯', 0x12F: 'æ§˜', 
    0x130: 'å…„', 0x131: 'å¼Ÿ', 0x132: 'å§‰', 0x133: 'å¦¹', 0x134: 'ç”·', 
    0x135: 'å¥³', 0x136: 'æ­©', 0x137: 'èµ°', 0x138: 'è²·', 0x139: 'å£²', 0x13A: 'å…¥',

    # --- Row 20 ---
    0x13B: 'å‡º', 0x13C: 'å¤§', 0x13D: 'ä¸­', 0x13E: 'å°', 0x13F: 'å¤š', 
    0x140: 'å°‘', 0x141: 'é•·', 0x142: 'å·¦', 0x143: 'å³', 0x144: 'å‰', 
    0x145: 'å¼±', 0x146: 'è¥¿', 0x147: 'å—', 0x148: 'åŒ—', 0x149: 'ä¸Š', 0x14A: 'ä¸‹',

    # --- Row 21 ---
    0x14B: 'é«˜', 0x14C: 'çŠ¬', 0x14D: 'ç‰›', 0x14E: 'é¦¬', 0x14F: 'é³¥', 
    0x150: 'ç¾Š', 0x151: 'è™«', 0x152: 'è²', 0x153: 'ç›®', 0x154: 'æ¯›', 
    0x155: 'ä½“', 0x156: 'æ­¯', 0x157: 'é ­', 0x158: 'é¦–', 0x159: 'å£°', 0x15A: 'é¡”',

    # --- Row 22 ---
    0x15B: 'æ‰‹', 0x15C: 'è¶³', 0x15D: 'ç”Ÿ', 0x15E: 'æ­»', 0x15F: 'å‘½', 
    0x160: 'èŠ±', 0x161: 'ç•‘', 0x162: 'é‡Ž', 0x163: 'èœ', 0x164: 'è‘‰', 
    0x165: 'è‰', 0x166: 'èŠ½', 0x167: 'èŒ¶', 0x168: 'è–¬', 0x169: 'ç¨®', 0x16A: 'æ¤',

    # --- Row 23 ---
    0x16B: 'è¾²', 0x16C: 'åˆˆ', 0x16D: 'æ–™', 0x16E: 'ç†', 0x16F: 'å‹•', 
    0x170: 'ç‰©', 0x171: 'æ„Ÿ', 0x172: 'è¬', 0x173: 'ç‰§', 0x174: 'å ´', 
    0x175: 'çµ', 0x176: 'å©š', 0x177: 'æ¸©', 0x178: 'æ³‰', 0x179: 'å¤©', 0x17A: 'å›½',

    # --- Row 24 ---
    0x17B: 'å‹‰', 0x17C: 'å¼·', 0x17D: 'ä¸€', 0x17E: 'äºŒ', 0x17F: 'å', 
    0x180: 'ä¸‡', 0x181: 'çŽ‹', 0x182: 'åŠ›', 0x183: 'å·¥', 0x184: 'æ–¹', 
    0x185: 'ä¸', 0x186: 'ä¸ˆ', 0x187: 'å¤«', 0x188: 'å‹', 0x189: 'åˆ', 0x18A: 'å…ƒ',

    # --- Row 25 ---
    0x18B: 'æ‰', 0x18C: 'å¤ª', 0x18D: 'ä»¥', 0x18E: 'å¤', 0x18F: 'ç”¨', 
    0x190: 'å¯', 0x191: 'å…ˆ', 0x192: 'ä»£', 0x193: 'å¤±', 0x194: 'åˆ‡', 
    0x195: 'å', 0x196: 'æˆ¸', 0x197: 'ã€…', 0x198: 'äºˆ', 0x199: 'å†…', 0x19A: 'åŒ¹',

    # --- Row 26 ---
    0x19B: 'åŒ–', 0x19C: 'ç¤º', 0x19D: 'å¹³', 0x19E: 'ç¤¼', 0x19F: 'åŠ', 
    0x1A0: 'åŽ»', 0x1A1: 'è¾º', 0x1A2: 'æ­¢', 0x1A3: 'ä»˜', 0x1A4: 'å¤–', 
    0x1A5: 'æ­£', 0x1A6: 'ä»•', 0x1A7: 'åŽ', 0x1A8: 'å¹»', 0x1A9: 'ç”±', 0x1AA: 'æœ¬',

    # --- Row 27 ---
    0x1AB: 'ä»Š', 0x1AC: 'å¿…', 0x1AD: 'è¡Œ', 0x1AE: 'æ—©', 0x1AF: 'è‡ª', 
    0x1B0: 'å', 0x1B1: 'å®ˆ', 0x1B2: 'ä¼‘', 0x1B3: 'å¥½', 0x1B4: 'æ±—', 
    0x1B5: 'åŒ', 0x1B6: 'è‚‰', 0x1B7: 'å½“', 0x1B8: 'æ›²', 0x1B9: 'å­¦', 0x1BA: 'æ¥',

    # --- Row 28 ---
    0x1BB: 'ä¼š', 0x1BC: 'å¼', 0x1BD: 'èˆŸ', 0x1BE: 'å°', 0x1BF: 'ç¾½', 
    0x1C0: 'å›£', 0x1C1: 'å›ž', 0x1C2: 'å¯¾', 0x1C3: 'ä¸–', 0x1C4: 'æ¬¡', 
    0x1C5: 'å®‰', 0x1C6: 'ä½•', 0x1C7: 'ä¼', 0x1C8: 'å…¨', 0x1C9: 'å¿˜', 0x1CA: 'è¿‘',

    # --- Row 29 ---
    0x1CB: 'è¿”', 0x1CC: 'å½¹', 0x1CD: 'åˆ', 0x1CE: 'åˆ©', 0x1CF: 'æ', 
    0x1D0: 'å†·', 0x1D1: 'æ±º', 0x1D2: 'èŠ¸', 0x1D3: 'è¦‹', 0x1D4: 'ä½œ', 
    0x1D5: 'è¨€', 0x1D6: 'å‘', 0x1D7: 'èµ¤', 0x1D8: 'å¹¸', 0x1D9: 'æ³¨', 0x1DA: 'æ´—',

    # --- Row 30 ---
    0x1DB: 'æ¶ˆ', 0x1DC: 'æ³£', 0x1DD: 'æ´»', 0x1DE: 'æ³¢', 0x1DF: 'æ³•', 
    0x1E0: 'ä¾›', 0x1E1: 'ä¾¡', 0x1E2: 'çš„', 0x1E3: 'åº¦', 0x1E4: 'å®Ÿ', 
    0x1E5: 'ç³¸', 0x1E6: 'è‹¦', 0x1E7: 'èº«', 0x1E8: 'å½¢', 0x1E9: 'å²©', 0x1EA: 'å®š',

    # --- Row 31 ---
    0x1EB: 'å­—', 0x1EC: 'æ”¾', 0x1ED: 'è¡¨', 0x1EE: 'å’Œ', 0x1EF: 'æžš', 
    0x1F0: 'æž—', 0x1F1: 'è»Š', 0x1F2: 'å›º', 0x1F3: 'å›', 0x1F4: 'åˆ¥', 
    0x1F5: 'å…·', 0x1F6: 'é¦™', 0x1F7: 'äº‹', 0x1F8: 'æ˜Ž', 0x1F9: 'å®¶', 0x1FA: 'ç„¶',

    # --- Row 32 ---
    0x1FB: 'è©±', 0x1FC: 'ç¾Ž', 0x1FD: 'æ¯', 0x1FE: 'è·', 0x1FF: 'å¸¸', 
    0x200: 'æ „', 0x201: 'æ€§', 0x202: 'å–', 0x203: 'åŽŸ', 0x204: 'ä¿‚', 
    0x205: 'ç¥ž', 0x206: 'å‘³', 0x207: 'å±‹', 0x208: 'è¨ˆ', 0x209: 'ä¿¡', 0x20A: 'å§‹',

    # --- Row 33 ---
    0x20B: 'ç‚¹', 0x20C: 'é¢', 0x20D: 'è¿·', 0x20E: 'ç§‘', 0x20F: 'å“', 
    0x210: 'æ€¥', 0x211: 'é€ƒ', 0x212: 'ç›¸', 0x213: 'æŒ‡', 0x214: 'å˜', 
    0x215: 'ç•Œ', 0x216: 'é’', 0x217: 'è¦', 0x218: 'æ—…', 0x219: 'æ•™', 0x21A: 'ç´…',

    # --- Row 34 ---
    0x21B: 'é€š', 0x21C: 'é“', 0x21D: 'è¨˜', 0x21E: 'è¨­', 0x21F: 'æ„›', 
    0x220: 'éƒ¨', 0x221: 'æ–°', 0x222: 'èƒ½', 0x223: 'é›†', 0x224: 'çœŸ', 
    0x225: 'å€‹', 0x226: 'é£Ÿ', 0x227: 'æ‹', 0x228: 'é€±', 0x229: 'æ¥­', 0x22A: 'èª­',

    # --- Row 35 ---
    0x22B: 'åœ°', 0x22C: 'è² ', 0x22D: 'ç›´', 0x22E: 'å¥´', 0x22F: 'å½¼', 
    0x230: 'è€ƒ', 0x231: 'ç‹©', 0x232: 'æ­Œ', 0x233: 'ä½¿', 0x234: 'è‚²', 
    0x235: 'é¤¨', 0x236: 'çµµ', 0x237: 'ç¬‘', 0x238: 'å³¶', 0x239: 'ç®±', 0x23A: 'éƒ½',

    # --- Row 36 ---
    0x23B: 'é£²', 0x23C: 'æŒ', 0x23D: 'é–‹', 0x23E: 'å¸«', 0x23F: 'ç¥­', 
    0x240: 'å¡©', 0x241: 'ç—…', 0x242: 'ç®—', 0x243: 'é£¼', 0x244: 'å¾…', 
    0x245: 'èªž', 0x246: 'ç´™', 0x247: 'å®¤', 0x248: 'æ‚²', 0x249: 'é‹', 0x24A: 'å§«',

    # --- Row 37 ---
    0x24B: 'æ¯', 0x24C: 'ç‰¹', 0x24D: 'æ ¹', 0x24E: 'è½', 0x24F: 'é–¢', 
    0x250: 'æ„', 0x251: 'å‹', 0x252: 'ä¹³', 0x253: 'é›²', 0x254: 'å±Š', 
    0x255: 'æ', 0x256: 'å€¤', 0x257: 'é ', 0x258: 'æŽ¢', 0x259: 'ç´š', 0x25A: 'æ•°',

    # --- Row 38 ---
    0x25B: 'ç­”', 0x25C: 'ç€', 0x25D: 'ç«¶', 0x25E: 'æ™¯', 0x25F: 'ç©', 
    # 0x262 is empty
    0x260: 'æƒ…', 0x261: 'èž',  0x263: 'ç§', 0x264: 'å›³', 
    0x265: 'æ›¸', 0x266: 'æ‰€', 0x267: 'æ€', 0x268: 'å¿ƒ', 0x269: 'é…', 0x26A: 'å­£',

    # --- Row 39 ---
    0x26B: 'ç¯€', 0x26C: 'é›¨', 0x26D: 'é›ª', 0x26E: 'ç™½', 0x26F: 'çŸ¥', 
    0x270: 'å­', 0x271: 'ä¸»', 0x272: 'äºº', 0x273: 'å£', 0x274: 'è€³', 
    0x275: 'ç«‹', 0x276: 'çŸ³', 0x277: 'ç”˜', 0x278: 'åœŸ', 0x279: 'è‰²', 0x27A: 'åºƒ',

    # --- Row 40 ---
    0x27B: 'åˆ', 0x27C: 'éŸ³', 0x27D: 'é‡‘', 0x27E: 'é­š', 0x27F: 'é…’', 
    0x280: 'å¸°', 0x281: 'å¨˜', 0x282: 'è¦ª', 0x283: 'æ©‹', 0x284: 'å®¢', 
    0x285: 'å¾Œ', 0x286: 'å¤¢', 0x287: 'ä»–', 0x288: 'æ¥½', 0x289: 'ç•ª', 0x28A: 'åœ’',

    # --- Row 41 ---
    0x28B: 'å•†', 0x28C: 'è€…', 0x28D: 'ç™º', 0x28E: 'å¥¥', 0x28F: 'æ•—', 
    0x290: 'æ ¡', 0x291: 'å™¨', 0x292: 'æ²¹', 0x293: 'å†™', 0x294: 'ç¬¬', 
    0x295: 'â‘ ', 0x296: 'â‘¡', 0x297: 'â‘¢', 0x298: 'â‘£', 0x299: 'â‘¤', 0x29A: 'â‘¥',

    # --- Row 42 ---
    0x29B: 'â‘¦', 0x29C: 'â‘§', 0x29D: 'â‘¨', 0x29E: 'â†–', 0x29F: 'â†˜', 
    0x2A0: 'â†—', 0x2A1: 'â†™',
}

CONTROL_CODES = {
    0: 'LINEBREAK',
    1: 'SOFTBREAK',
    2: 'TEXTEND',
    3: 'WAIT',  # Followed by 1-byte duration parameter
    4: 'WAIT_WITH_ICON',
    5: 'LOAD_TEXT',  # Followed by 2-byte text index
    6: 'RESERVED',
    7: 'INSERT_GAMEVAR', # Followed by 1-byte string index
    8: 'WAIT_VARIANT',
    9: 'CHARACTER_AVATAR', # Followed by 1-byte animation index
}

BIT_MASKS = [0x80, 0x40, 0x20, 0x10, 0x08, 0x04, 0x02, 0x01]

def get_offset_array(index_start, index_end):

    if rom is None:
        set_rom()

    num_entries = int((index_end - index_start) // 4)

    offsets = np.frombuffer(rom, dtype=np.dtype(">u4"), count=num_entries, offset=index_start)

    # handle offset arrays that have 0 padding at the end

    # get indices of all non-zero elements 
    nonzeros = np.nonzero(offsets)[0]
    # get last non-zero index
    last = nonzeros[-1] if len(nonzeros) > 0 else 0
    
    # trim original array
    return offsets[:last+1]

def set_text_segments(index_start: int, index_end: int, text_start: int) -> dict:

    # Text data ends at the start of its own index table
    text_end = index_start

    # Maximum valid offset - offsets at or past this point to the index table
    max_valid_offset = index_start - text_start

    if VERBOSE == True:
        print(f"Text bank layout:")
        print(f"  Index: 0x{index_start:08X} - 0x{index_end:08X}")
        print(f"  Text:  0x{text_start:08X} - 0x{text_end:08X}")
        print(f"  Max valid offset: 0x{max_valid_offset:04X}")

    index_size = index_end - index_start
    index_count = index_size // 4

    if VERBOSE == True:
        print(f"  Index size: {index_size} bytes, {index_count} entries")

    offsets = get_offset_array(index_start, index_end)

    # Calculate start addresses and sizes for each valid text segment
    segments = []

    for idx, offset in enumerate(offsets):

        start_address = text_start + offset

        # Calculate size by getting difference between segments or between text_end and last segment
        if idx + 1 < len(offsets):
            next_offset = offsets[idx + 1]
            # Cap next_offset at max_valid_offset to avoid reading into index table
            if next_offset > max_valid_offset:
                next_offset = max_valid_offset
            next_start = text_start + next_offset
            size = next_start - start_address
        else:
            # Last segment goes to the start of the index table
            size = text_end - start_address

        # Mark segments that point at or past the text data end as terminators
        # These are kept for index table generation but have no extractable text
        is_terminator = offset >= max_valid_offset

        if size < 0:
            if VERBOSE == True:
                print(f"  WARNING: Segment {idx} has invalid size {size} bytes")
            size = 0

        if VERBOSE == True:
            term_str = " (terminator)" if is_terminator else ""
            print(f"  Segment {idx} (index {idx}): 0x{start_address:08X}, size {size} bytes{term_str}")

        segments.append({
            'index': idx,
            'start_address': start_address,
            'size': size,
            'offset': offset,
            'is_terminator': is_terminator
        })
    
    return {
        'index_count': index_count,
        'segments': segments,
        'index_start': index_start,
        'index_end': index_end,
        'text_start': text_start,
        'text_end': text_end
    }

class TextDecoder:

    def __init__(self):
        self.position = 0
        self.char_counter = 0
        self.control_byte = 0
        
    def decode_stream(self, byte_data, literal_mode=False):
        """
        Decode a byte stream into a list of decoded items.
        
        Args:
            byte_data: Bytes, hex string, or list of bytes
            literal_mode: If True, parse entire segment including content after TEXTEND
                         (needed for byte-perfect round-trip recompilation).
                         If False, stop at TEXTEND for human-readable output.
        """

        if isinstance(byte_data, str):
            # Convert hex string to bytes
            byte_data = bytes.fromhex(byte_data.replace(' ', ''))

        elif isinstance(byte_data, list):
            byte_data = bytes(byte_data)
            
        self.position = 0
        self.char_counter = 0
        self.control_byte = 0
        self._current_data = byte_data  # Store reference for parameter extraction
        result = []
        
        while self.position < len(byte_data):

            decoded_value = self._decode_next_character(byte_data)
            
            if decoded_value is not None:
                result.append(decoded_value)

                # In non-literal mode, stop at TEXTEND for readability
                # In literal mode, continue parsing to capture trailing content for byte-matching
                if not literal_mode and isinstance(decoded_value, dict):
                    if decoded_value.get('type') == 'control' and decoded_value.get('name') == 'TEXTEND':
                        if VERBOSE:
                            remaining = byte_data[self.position:]
                            print(f"    Stopping at TEXTEND. Remaining bytes: {remaining.hex()}")
                        break

                # Check if this is a segment-ending control code (legacy behavior)
                if isinstance(decoded_value, dict) and decoded_value.get('segment_end'):
                    if VERBOSE == True:
                        print(f"    Decode stopped at WAITINPUT at position {self.position}/{len(byte_data)}")
                    break
            
            else:

                if VERBOSE == True:
                
                    # stop if next character can't be decoded
                    print(f"    Decode stopped at position {self.position}/{len(byte_data)}")
                    
                    # Show the last few bytes for debugging
                    start_pos = max(0, self.position - 10)
                    end_pos = min(len(byte_data), self.position + 10)
                    context_bytes = byte_data[start_pos:end_pos]
                    
                    print(f"    Context bytes around position {self.position}: {context_bytes.hex()}")

                break
                
        return result
    
    def _decode_next_character(self, data):

        if self.position >= len(data):
            if VERBOSE == True:
                print(f"    EOF reached at position {self.position}")
            return None
            
        # Read new control byte every 8 characters
        if self.char_counter % 8 == 0:

            if self.position >= len(data):
                if VERBOSE == True:
                    print(f"    EOF while reading control byte at position {self.position}")
                return None

            self.control_byte = data[self.position]
            
            if VERBOSE == True:
                print(f"    Char {self.char_counter}: New control byte 0x{self.control_byte:02X} at position {self.position}")
            
            self.position += 1
            
        if self.position >= len(data):
            if VERBOSE == True:
                print(f"    EOF after control byte at position {self.position}")
            return None
            
        # Check if this character position needs 2-byte encoding
        bit_index = self.char_counter % 8
        needs_two_bytes = (self.control_byte & BIT_MASKS[bit_index]) != 0
        
        if VERBOSE == True:
            print(f"    Char {self.char_counter}: bit_index={bit_index}, needs_two_bytes={needs_two_bytes}")
        
        if needs_two_bytes:
            
            # Read 2 bytes for control command
            if self.position + 1 >= len(data):
                # Not enough data for 2-byte read - this is an edge case at segment end
                # Output remaining byte; round-trip check will catch if this causes issues
                if self.position < len(data):
                    remaining_byte = data[self.position]
                    self.position += 1
                    self.char_counter += 1
                    if VERBOSE == True:
                        print(f"    Incomplete 2-byte read at segment end, byte 0x{remaining_byte:02X}")
                    return f'[CHAR:0x{remaining_byte:02X}]'
                return None

            byte1 = data[self.position]
            byte2 = data[self.position + 1]

            self.position += 2

            # byteswap 16-bit values
            result = byte1 | (byte2 << 8) 
            
            if result in CHAR_MAP:
                decoded = CHAR_MAP[result]
                if VERBOSE == True:
                    print(f"    Read 2-byte character: 0x{result:04X} -> '{decoded}'")

            elif result == 0:
                if VERBOSE == True:
                    print(f"    Found null terminator (0x0000), ending decode")
                return None

            else:
                # Invalid 2-byte code - preserve as [WORD:0xXXXX] for round-trip
                # The transpiler will encode this as a 2-byte value (control bit set)
                decoded = f'[WORD:0x{result:04X}]'
                if VERBOSE == True:
                    print(f"    Invalid 2-byte code 0x{result:04X} -> [WORD:0x{result:04X}]")
                
        else:
            # Read 1 byte
            byte_val = data[self.position]
            self.position += 1
    
            result = byte_val
            decoded = self._decode_character(result)
    
            if VERBOSE == True:
                print(f"    Read 1-byte character: 0x{result:02X} -> {decoded}")
            
        self.char_counter += 1
        
        # sanity check if addresses are messed up
        if self.char_counter > 5000:
            print(f"    ERROR: Processed {self.char_counter} characters - likely incorrect segment size")
            print(f"    Current position: {self.position}/{len(data)} bytes")
            return None
            
        return decoded
    
    def _extract_parameter(self, control_code):
        """Extract parameter bytes that follow certain control codes"""

        if VERBOSE == True:
            print(f"      Extracting parameter for control code {control_code}")
        
        if control_code == 5:  # LOAD_TEXT - 2-byte little-endian parameter
        
            if hasattr(self, '_current_data') and self.position + 1 < len(self._current_data):
                byte1 = self._current_data[self.position]
                byte2 = self._current_data[self.position + 1]
                self.position += 2
                # DON'T increment char_counter here - it messes up control byte timing
                param = byte1 | (byte2 << 8)  # Little endian
    
                if VERBOSE == True:
                    print(f"      Extracted 2-byte parameter: 0x{param:04X}")
    
                return param    
        
        elif control_code in [3, 7, 9]:  # WAIT, INSERT_GAMEVAR, CHAR_ANIMATION - 1-byte parameter

            if hasattr(self, '_current_data') and self.position < len(self._current_data):

                param = self._current_data[self.position]
                self.position += 1

                # don't increment char_counter here

                if VERBOSE == True:
                    print(f"      Extracted 1-byte parameter: 0x{param:02X}")

                return param

        return None
    
    def _decode_character(self, value):

        if value in CONTROL_CODES:

            control_name = CONTROL_CODES[value]

            # Extract parameter if this control code needs one
            param = self._extract_parameter(value)

            if param is not None:
                return {'type': 'control', 'code': value, 'name': control_name, 'parameter': param}
            else:
                return {'type': 'control', 'code': value, 'name': control_name}
            
        elif value in CHAR_MAP:
            return {'type': 'character', 'value': CHAR_MAP[value]}
        else:
            # Show both the raw value and after -0xB
            font_index = value - 0xB if value >= 0xB else value
            return {'type': 'unknown', 'raw': value, 'font_index': font_index}
    
    def decode_and_format(self, byte_data, literal_mode=False):
        """
        Decode and format as readable text with enhanced control code handling.
        
        Args:
            byte_data: The binary data to decode
            literal_mode: If True, output exact control codes and parse entire segment
                         (for byte-perfect recompilation).
                         If False, stop at TEXTEND and use friendly formatting with 
                         newlines (for human reading).
        """

        decoded = self.decode_stream(byte_data, literal_mode=literal_mode)
        result = []
        
        for item in decoded:
        
            if isinstance(item, dict):
        
                if item['type'] == 'control':
        
                    if 'parameter' in item:
                        result.append(f"[{item['name']}:{item['parameter']:02X}]")
                    else:
                        if literal_mode:
                            # Literal mode: just the control code, no extra formatting
                            result.append(f"[{item['name']}]")
                        else:
                            # Friendly mode: natural newlines, implicit TEXTEND
                            if item['name'] == 'LINEBREAK':
                                result.append('\n')  # Natural newline
                            elif item['name'] == 'SOFTBREAK':
                                result.append('\n')  # Natural newline (soft)
                            elif item['name'] == 'TEXTEND':
                                pass  # Implicit - omit in friendly mode
                            else:
                                result.append(f"[{item['name']}]")
        
                elif item['type'] == 'character':
                    result.append(item['value'])
        
                elif item['type'] == 'unknown':
                    result.append(f"[CHAR:0x{item['raw']:02X}â†’0x{item['font_index']:02X}]")
        
            else:
                # Fallback for old format
                result.append(str(item))
        
        return ''.join(result)

def decode_text_bank(index_start: int, index_end: int, text_start: int, literal_mode: bool = False) -> list:
    """
    Decode a text bank from ROM.
    
    Args:
        index_start: ROM address of index table start
        index_end: ROM address of index table end  
        text_start: ROM address of text data start
        literal_mode: If True, output exact control codes for recompilation.
                     If False, output friendly format with newlines for reading.
    """
    
    if rom is None:
        set_rom()
    
    bank_info = set_text_segments(index_start, index_end, text_start)
    decoder = TextDecoder()
    decoded_texts = []
    
    for segment in bank_info['segments']:

        # Skip terminator segments - they mark the end of text data for index calculation
        # but have no actual text content to decode
        if segment.get('is_terminator', False):
            if VERBOSE == True:
                print(f"Skipping terminator segment {segment['index']}: offset 0x{segment['offset']:04X}")
            decoded_texts.append({
                'index': segment['index'],
                'start_address': f"0x{segment['start_address']:08X}",
                'size': 0,
                'actual_size': 0,
                'offset': segment['offset'],
                'is_terminator': True,
                'decoded_text': '',
                'raw_data': ''
            })
            continue

        if VERBOSE == True:
            print(f"Processing segment {segment['index']}: 0x{segment['start_address']:08X}, calculated size: {segment['size']}")

        segment_data = rom[segment['start_address']:segment['start_address'] + segment['size']]
        actual_size = len(segment_data)

        if VERBOSE == True:
            print(f"  Actual segment_data size: {actual_size} bytes")
            if actual_size >= 16:
                print(f"  Last 16 bytes: {segment_data[-16:].hex()}")
                print(f"  First 16 bytes: {segment_data[:16].hex()}")

        # Check if segment is all zeros (padding, not actual text content)
        # These segments exist in the index but contain only padding bytes
        if actual_size > 0 and all(b == 0 for b in segment_data):
            if VERBOSE:
                print(f"  Segment {segment['index']} is padding ({actual_size} bytes of zeros)")
            decoded_texts.append({
                'index': segment['index'],
                'start_address': f"0x{segment['start_address']:08X}",
                'size': segment['size'],
                'actual_size': actual_size,
                'offset': segment['offset'],
                'is_padding': True,
                'decoded_text': '',
                'raw_data': segment_data[:50].hex()
            })
            continue

        try:

            if VERBOSE == True:
                print(f"  Starting decode for segment {segment['index']}...")

            decoded = decoder.decode_and_format(segment_data, literal_mode=literal_mode)

            # Check if this is a mid-stream loaded segment that won't round-trip correctly
            # Two indicators: starts with [CHAR:0xXX], or re-encoding produces different bytes
            needs_rawbytes = False

            # Check 1: starts with [CHAR:0xXX] pattern
            if re.match(r'^\[CHAR:0x[0-9A-Fa-f]{2}\]', decoded):
                needs_rawbytes = True

            # Check 2: try re-encoding and compare (only for small segments to avoid performance issues)
            if not needs_rawbytes and len(segment_data) <= 64:
                try:
                    from hm64_text_transpiler import TextEncoder
                    test_encoder = TextEncoder()
                    test_encoder.auto_textend = False
                    test_encoder.convert_newlines = False
                    # Strip trailing padding from comparison
                    reencoded = test_encoder.encode_text(decoded)
                    original_trimmed = bytes(segment_data).rstrip(b'\x00')
                    reencoded_trimmed = reencoded.rstrip(b'\x00')
                    if original_trimmed != reencoded_trimmed:
                        needs_rawbytes = True
                        if VERBOSE:
                            print(f"  Segment {segment['index']} round-trip mismatch: {original_trimmed.hex()} vs {reencoded_trimmed.hex()}")
                except Exception as e:
                    if VERBOSE:
                        print(f"  Could not verify round-trip for segment {segment['index']}: {e}")

            if needs_rawbytes:
                # Use RAWBYTES directive with commented interpretation
                byte_interpretation = []
                for b in segment_data:
                    if b in CONTROL_CODES:
                        byte_interpretation.append(f'[{CONTROL_CODES[b]}]')
                    elif b in CHAR_MAP:
                        byte_interpretation.append(CHAR_MAP[b])
                    else:
                        byte_interpretation.append(f'[0x{b:02X}]')
                interpretation = ''.join(byte_interpretation)
                decoded = f'[RAWBYTES:{segment_data.hex()}]\n# Byte interpretation: {interpretation}'
                if VERBOSE == True:
                    print(f"  Segment {segment['index']} converted to RAWBYTES (mid-stream loaded)")

            if VERBOSE == True:
                print(f"  Successfully decoded segment {segment['index']}")

            decoded_texts.append({
                'index': segment['index'],
                'start_address': f"0x{segment['start_address']:08X}",
                'size': segment['size'],
                'actual_size': actual_size,
                'offset': segment['offset'],
                'decoded_text': decoded,
                'raw_data': segment_data[:50].hex() + ('...' if segment['size'] > 50 else '')
            })

        except Exception as e:
            print(f"  Error decoding segment {segment['index']}: {e}")
            decoded_texts.append({
                'index': segment['index'],
                'start_address': f"0x{segment['start_address']:08X}",
                'size': segment['size'],
                'actual_size': actual_size,
                'offset': segment['offset'],
                'error': str(e),
                'raw_data': segment_data[:50].hex() + ('...' if segment['size'] > 50 else '')
            })
    
    return decoded_texts

def write_text_bank_to_files(index_start: int, index_end: int, text_start: int, output_dir: str = None, literal_mode: bool = False) -> str:
    """
    Extract a text bank from ROM and write to individual text files.
    
    Args:
        index_start: ROM address of index table start
        index_end: ROM address of index table end
        text_start: ROM address of text data start
        output_dir: Output directory name (optional)
        literal_mode: If True, output exact control codes for recompilation.
                     If False, output friendly format with newlines for reading.
    """
    if rom is None:
        set_rom()
    
    if output_dir is None:
        output_dir = f"text-block-0x{text_start:08X}"
    
    assets_path = Path(__file__).parent.parent.parent / "assets" / "text"
    output_path = assets_path / output_dir
    
    output_path.mkdir(parents=True, exist_ok=True)
    
    decoded_texts = decode_text_bank(index_start, index_end, text_start, literal_mode=literal_mode)

    files_written = 0
    for text_info in decoded_texts:

        # Skip terminator segments - they have no text content to write
        if text_info.get('is_terminator', False):
            if VERBOSE:
                print(f"Skipping terminator segment {text_info['index']} (no file created)")
            continue

        # Skip padding segments - all zeros, no text content
        if text_info.get('is_padding', False):
            if VERBOSE:
                print(f"Skipping padding segment {text_info['index']} ({text_info['size']} bytes of zeros)")
            continue

        filename = f"text{text_info['index']:03d}.txt"
        file_path = output_path / filename

        with open(file_path, 'w', encoding='utf-8') as f:

            f.write(f"# Text Segment {text_info['index']}\n")
            f.write(f"# Address: {text_info['start_address']}\n")
            f.write(f"# Size: {text_info['size']} bytes\n")
            f.write(f"# Raw data: {text_info['raw_data']}\n")
            f.write("# " + "="*60 + "\n")

            if 'error' in text_info:
                f.write(f"ERROR: {text_info['error']}\n")
            else:
                f.write(text_info['decoded_text'])

        files_written += 1

    # Write bank metadata file with terminator info for the transpiler
    metadata_path = output_path / "_metadata.txt"
    with open(metadata_path, 'w', encoding='utf-8') as f:
        f.write("# Text Bank Metadata\n")
        f.write(f"# INDEX_START: 0x{index_start:08X}\n")
        f.write(f"# INDEX_END: 0x{index_end:08X}\n")
        f.write(f"# TEXT_START: 0x{text_start:08X}\n")
        f.write(f"# TOTAL_SEGMENTS: {len(decoded_texts)}\n")
        f.write("\n")

        # List terminator segments (segments with no text content that mark end of data)
        terminators = [t for t in decoded_texts if t.get('is_terminator', False)]
        if terminators:
            f.write("# Terminator segments (index table entries with no text data):\n")
            for term in terminators:
                f.write(f"TERMINATOR: {term['index']}\n")
            f.write("\n")

        # List padding segments (all-zero segments, transpiler emits .space N)
        padding_segments = [t for t in decoded_texts if t.get('is_padding', False)]
        if padding_segments:
            f.write("# Padding segments (all zeros, no text file generated):\n")
            for pad in padding_segments:
                f.write(f"PADDING: {pad['index']} SIZE: {pad['size']}\n")

    print(f"Wrote {files_written} text files to directory: {output_path.absolute()}")

    return str(output_path.absolute())

def load_text_addresses() -> list:

    if not CSV_PATH.exists():
        print(f"CSV file not found: {CSV_PATH}")
        return []
    
    text_banks = []

    with open(CSV_PATH, 'r', newline='', encoding='utf-8') as csvfile:

        reader = csv.DictReader(csvfile)
        
        for row in reader:

            try:
                index_start = int(row['index_start'], 16)
                index_end = int(row['index_end'], 16)
                text_start = int(row['text_start'], 16)
                game_index = int(row['game_index']) if 'game_index' in row else 0
                
                text_banks.append({
                    'name': row['name'].strip(),
                    'index_start': index_start,
                    'index_end': index_end,
                    'text_start': text_start,
                    'game_index': game_index
                })
                
            except (ValueError, KeyError) as e:
                print(f"Error parsing CSV row {row}: {e}")
                continue
    
    return text_banks

def process_all_text_banks(command: str = 'write_files'):

    text_banks = load_text_addresses()

    if not text_banks:
        print("No text banks found in CSV file.")
        return
    
    if VERBOSE == True:
        print(f"Found {len(text_banks)} text banks in {CSV_PATH}")
    
    for bank in text_banks:

        if VERBOSE == True:
            print(f"\n--- Processing '{bank['name']}' ---")
            print(f"Index: 0x{bank['index_start']:08X} - 0x{bank['index_end']:08X}")
            print(f"Text:  0x{bank['text_start']:08X} - 0x{bank['index_start']:08X}")
        
        try:

            if command == 'write_files':
                output_path = write_text_bank_to_files(bank['index_start'], bank['index_end'], bank['text_start'], bank['name'], literal_mode=LITERAL_MODE)
                print(f"Files written to: {output_path}")
                
            elif command == 'decode_bank':
                decoded_texts = decode_text_bank(bank['index_start'], bank['index_end'], bank['text_start'], literal_mode=LITERAL_MODE)
                
            elif command == 'analyze_bank':
                set_rom()
                bank_info = set_text_segments(bank['index_start'], bank['index_end'], bank['text_start'])
                
                if VERBOSE == True:
                    print(f"  Total segments: {bank_info['index_count']}")
                
        except Exception as e:
            print(f"Error processing '{bank['name']}': {e}")

def main():

    if len(sys.argv) < 2:
        print("Usage:")
        print("  python hm64_text_utilities.py extract_bank <bank_name> [--literal]")
        print("  python hm64_text_utilities.py decode_bank <index_start> <index_end> <text_start> [--literal]")
        print("  python hm64_text_utilities.py analyze_bank <index_start> <index_end> <text_start>")
        print("  python hm64_text_utilities.py write_files <index_start> <index_end> <text_start> [output_dir] [--literal]")
        print("  python hm64_text_utilities.py process_all [write_files|decode_bank|analyze_bank] [--literal]")
        print("  python hm64_text_utilities.py list_banks")
        print("")
        print("Options:")
        print("  --verbose   Enable verbose output")
        print("  --literal   Output exact control codes for recompilation (vs friendly for reading)")
        sys.exit(1)

    cmd = sys.argv[1]

    if cmd == "extract_bank":

        # Extract a single bank by name (looks up addresses in CSV)
        if len(sys.argv) >= 3:
            
            bank_name = sys.argv[2]
            
            text_banks = load_text_addresses()
            
            if not text_banks:
                print("ERROR: Could not load text bank addresses from CSV")
                sys.exit(1)
            
            # Find the requested bank
            bank_info = None
            for bank in text_banks:
                if bank['name'] == bank_name:
                    bank_info = bank
                    break
            
            if bank_info is None:
                print(f"ERROR: Text bank '{bank_name}' not found in CSV")
                print("Available banks:")
                for bank in text_banks:
                    print(f"  - {bank['name']}")
                sys.exit(1)
            
            if VERBOSE:
                print(f"Extracting text bank '{bank_name}':")
                print(f"  Index: 0x{bank_info['index_start']:08X} - 0x{bank_info['index_end']:08X}")
                print(f"  Text:  0x{bank_info['text_start']:08X}")
            
            output_path = write_text_bank_to_files(
                bank_info['index_start'],
                bank_info['index_end'],
                bank_info['text_start'],
                bank_name,
                literal_mode=LITERAL_MODE
            )

            print(f"Extracted to: {output_path}")
            
        else:
            print("Please provide a bank name")
            print("Use 'list_banks' to see available banks")
            sys.exit(1)

    elif cmd == "decode_bank":

        if len(sys.argv) >= 5:

            index_start = int(sys.argv[2], 16)
            index_end = int(sys.argv[3], 16)
            text_start = int(sys.argv[4], 16)
            
            print(f"Decoding text bank:")
            print(f"Index: 0x{index_start:08X} - 0x{index_end:08X}")
            print(f"Text:  0x{text_start:08X}")
            
            decoded_texts = decode_text_bank(index_start, index_end, text_start, literal_mode=LITERAL_MODE)
            
            for text_info in decoded_texts:
                
                print(f"\n--- Text {text_info['index']} ---")
                print(f"Address: {text_info['start_address']}")
                print(f"Size: {text_info['size']} bytes")
                
                if 'error' in text_info:
                    print(f"Error: {text_info['error']}")
                else:
                    print(f"Text: {text_info['decoded_text']}")

                print(f"Raw data: {text_info['raw_data']}")
                
        else:
            print("Please provide index_start, index_end, and text_start addresses in hex")
            sys.exit(1)
            
    elif cmd == "analyze_bank":

        if len(sys.argv) >= 5:

            index_start = int(sys.argv[2], 16)
            index_end = int(sys.argv[3], 16)
            text_start = int(sys.argv[4], 16)
            
            set_rom()
            bank_info = set_text_segments(index_start, index_end, text_start)
            
            print(f"Text Bank Analysis:")
            print(f"Index: 0x{index_start:08X} - 0x{index_end:08X}")
            print(f"Text:  0x{text_start:08X}")
            print(f"Total segments: {bank_info['index_count']}")
            print(f"\nSegment breakdown:")
            
            for segment in bank_info['segments']:
                print(f"  {segment['index']:3d}: 0x{segment['start_address']:08X} (offset +0x{segment['offset']:04X}) - {segment['size']:4d} bytes")
                
        else:
            print("Please provide index_start, index_end, and text_start addresses in hex")
            sys.exit(1)
            
    elif cmd == "write_files":

        if len(sys.argv) >= 5:
        
            index_start = int(sys.argv[2], 16)
            index_end = int(sys.argv[3], 16)
            text_start = int(sys.argv[4], 16)
            
            # Optional custom directory name
            output_dir = sys.argv[5] if len(sys.argv) >= 6 else None
            
            print(f"Writing text bank files:")
            print(f"Index: 0x{index_start:08X} - 0x{index_end:08X}")
            print(f"Text:  0x{text_start:08X}")
            
            output_path = write_text_bank_to_files(index_start, index_end, text_start, output_dir, literal_mode=LITERAL_MODE)
            print(f"Files written to: {output_path}")
            
        else:
            print("Please provide index_start, index_end, and text_start addresses in hex")
            sys.exit(1)
            
    elif cmd == "process_all":

        command = sys.argv[2] if len(sys.argv) >= 3 else 'write_files'
        
        if command not in ['write_files', 'decode_bank', 'analyze_bank']:
            print(f"Unknown command for process_all: {command}")
            print("Available commands: write_files, decode_bank, analyze_bank")
            sys.exit(1)

        process_all_text_banks(command)
        
    elif cmd == "list_banks":

        text_banks = load_text_addresses()

        if not text_banks:
            print("No text banks found in CSV file.")
        else:
            print(f"Text banks found in {CSV_PATH}:")
            for i, bank in enumerate(text_banks):
                game_idx = f"(game:{bank['game_index']:02X})" if 'game_index' in bank else ""
                print(f"  {i+1:2d}. {bank['name']:15s} {game_idx:10s} Index: 0x{bank['index_start']:08X}-0x{bank['index_end']:08X} Text: 0x{bank['text_start']:08X}-0x{bank['index_start']:08X}")
    
    else:
        print(f"Unknown command: {cmd}")
        print("Available commands: extract_bank, decode_bank, analyze_bank, write_files, process_all, list_banks")

if __name__ == "__main__":
    main()